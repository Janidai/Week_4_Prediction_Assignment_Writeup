---
title: "Week_4_Prediction_Assignment_Writeup"
author: "Abdellah Janid"
date: "20/01/2020"
output:
  pdf_document:
    fig_caption: yes
    number_sections: yes
    toc: yes
  html_document:
    fig_caption: yes
    number_sections: yes
    toc: yes
csl: apa.csl
bibliography: bibliography.bib

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```


```{r warning=FALSE,message=FALSE}
#load necessary R packages
library(knitr)
library(dplyr)
library(caret)
library(rpart)
library(rpart.plot)
library(rattle)
library(randomForest)
library(corrplot)
library(e1071)
set.seed(301)
```


# Introduction

The following assignment aims to predict the manner in which the participant did an exercise

in uses [@halpern_index_2012]


# Load Data and cleaning data
The training data for this project are available here:
- [Project and Research paper](http://groupware.les.inf.puc-rio.br/har]http://groupware.les.inf.puc-rio.br/har)
- [Training Set](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv)
- [Test Set](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv)




# Research question


# Study design

## Data
To answer the research question, an appropreate data is needed. 
The data `r dim()` which is considered a large data set, therefore the chosen partitioning strategy is the following

## Training dataset and Cross validation approach:

### Random subsampling
### K-fold cross validation

**1. Use the training set**
The original training data set will be split into two 
**2. Split it into trainning/test sets**
**3. Build a model on the training set**
**4. Evaluate on the test set**
**5. Repeat and average the estimated errors**

## Testing dataset

## Features

# Modelling

What is the confusion matrix?

Sensistivity?
Specifity?
Positice Predictive value?
Negative Predictive value?
Accuracy?



## Evaluation

Do we have overfitting problem?
What is in the sample error? give example for this case?
What is out of the sample error? give example for this case?
How do we handle in and out of the sample error?



## Prediction




https://www.coursera.org/learn/practical-machine-learning/lecture/HZKcr/cross-validation
What is cross validation?
  What is random subsampling with replacement and without replacement?
  what is K-fold?
  what is leave one out?






The next step is loading the dataset from the URL provided above. The training dataset is then partinioned in 2 to create a Training set (70% of the data) for the modeling process and a Test set (with the remaining 30%) for the validations.

The testing dataset is not changed and will only be used for the quiz results generation.

```{r get_raw_data}
data_set_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testing_set_quiz_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
data_set_path <- "data/pml-traininig.csv" # set path and name of the file of the training dataset
testing_set_quiz_path <- "data/pml-testing.csv" # set path and name of the file of to the testing dataset


# If the file does not exist
if (!file.exists(data_set_path)) {
  download.file(data_set_url, destfile = data_set_path) # download the datasets
}
training <- read.csv(training_set_path) # read the file

if (!file.exists(testing_set_path)) {
  download.file(testing_set_url, destfile = testing_set_path)
}
testing_quiz <- read.csv(testing_set_path)
```


```{r partition_data}
# create a partition using caret with the training dataset on 80,20 ratio
inTrain  <- createDataPartition(training$classe,
                                p=0.8, # Specify the percentage of data to use for the training set, 80% for training and 20 for testing
                                list=FALSE) #result a matrix and not a list

training <- training[inTrain, ] #subset data into training set

testing  <- training[-inTrain, ]#subset data into testing set
dim(training)
```

```{r}
dim(testing)
```

Both created datasets have 160 variables. Letâ€™s clean NA, The Near Zero variance (NZV) variables and the ID variables as well.

```{r}
# remove variables with Nearly Zero Variance
NZV <- nearZeroVar(training)
training <- training[, -NZV]
testing  <- testing[, -NZV]
dim(testing)
```

```{r}
dim(training)
```

```{r}
# remove variables that are mostly NA
AllNA    <- sapply(training, function(x) mean(is.na(x))) > 0.95
training <- training[, AllNA==FALSE]
testing  <- testing[, AllNA==FALSE]
dim(testing)
```

```{r}
dim(training)
```

```{r}
# remove identification only variables (columns 1 to 5)
training <- training[, -(1:5)]
testing  <- testing[, -(1:5)]
dim(training)
```
After cleaning, we can see that the number of vairables for the analysis are now only 53.

# Exploratory analysis

A correlation among variables is analysed before proceeing to the modeling procedures.

```{r}
corMatrix <- cor(training[, -54])
corrplot(corMatrix, order = "FPC", method = "color", type = "lower",
         tl.cex = 0.8, tl.col = rgb(0, 0, 0))
```

The highly correlated variables are shown in dark colors in the graph above. To make an even more compact analysis, a PCA (Principal Components Analysis) could be performed as pre-processing step to the datasets. Nevertheless, as the correlations are quite few, this step will not be applied for this assignment.

# Modelling
Three popular methods will be applied to model the regressions (in the Train dataset) and the best one (with higher accuracy when applied to the Test dataset) will be used for the quiz predictions. The methods are: Random Forests, Decision Tree and Generalized Boosted Model, as described below. A Confusion Matrix is plotted at the end of each analysis to better visualize the accuracy of the models.

## Random Forests
```{r}
# model fit
set.seed(301)
controlRF <- trainControl(method="cv", number=3, verboseIter=FALSE)
modFitRandForest <- train(classe ~ ., data=training, method="rf", trControl=controlRF)
modFitRandForest$finalModel
```

```{r}
# prediction on Test dataset
predictRandForest <- predict(modFitRandForest, newdata=testing)
confMatRandForest <- confusionMatrix(predictRandForest, testing$classe)
confMatRandForest
```


```{r}
# plot matrix results
plot(confMatRandForest$table, col = confMatRandForest$byClass,
     main = paste("Random Forest - Accuracy =",
                  round(confMatRandForest$overall['Accuracy'], 4)))
```


## Decision tree
```{r}
# model fit
set.seed(301)
modFitDecTree <- rpart(classe ~ ., data=training, method="class")
fancyRpartPlot(modFitDecTree)
```

```{r}
# prediction on Test dataset
predictDecTree <- predict(modFitDecTree, newdata=testing, type="class")
confMatDecTree <- confusionMatrix(predictDecTree, testing$classe)
confMatDecTree
```

```{r}
# plot matrix results
plot(confMatDecTree$table, col = confMatDecTree$byClass,
     main = paste("Decision Tree - Accuracy =",
                  round(confMatDecTree$overall['Accuracy'], 4)))
```

##  Generalized Boosted Model (GBM)
```{r}
# model fit
set.seed(301)
controlGBM <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
modFitGBM  <- train(classe ~ ., data=training, method = "gbm",
                    trControl = controlGBM, verbose = FALSE)
```

```{r}
modFitGBM$finalModel
```

```{r}
# prediction on Test dataset
predictGBM <- predict(modFitGBM, newdata=testing)
confMatGBM <- confusionMatrix(predictGBM, testing$classe)
confMatGBM
```

```{r}
# plot matrix results
plot(confMatGBM$table, col = confMatGBM$byClass,
     main = paste("GBM - Accuracy =", round(confMatGBM$overall['Accuracy'], 4)))
```

# Applying the selected Model to the Test Data
The accuracy of the 3 regression modeling methods above are:

- Random Forest : 0.9968
- Decision Tree : 0.8291
- GBM : 0.9884
In that case, the Random Forest model will be applied to predict the 20 quiz results (testing dataset) as shown below.

```{r}
predictTEST <- predict(modFitRandForest, newdata=testing_quiz)
predictTEST
```

# References
Bibliography list: